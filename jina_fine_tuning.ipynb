{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U finetuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import obsidiantools.api as otools\n",
    "\n",
    "# two level above the current directory\n",
    "wkd = Path(os.getcwd()).parent.parent.parent\n",
    "vault = otools.Vault(wkd).connect().gather()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docarray import Document, DocumentArray\n",
    "\n",
    "train_da = DocumentArray()\n",
    "\n",
    "for k, v in vault.text_index.items():\n",
    "    train_da.append(Document(content=v, tags={\"finetuner_label\": vault.get_tags(k)}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                Finetuner backbones                                                </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">                                       name </span>┃<span style=\"font-weight: bold\">     task </span>┃<span style=\"font-weight: bold\"> out… </span>┃<span style=\"font-weight: bold\"> archi… </span>┃<span style=\"font-weight: bold\">                             description </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                            bert-base-cased </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> text-to… </span>│<span style=\"color: #008080; text-decoration-color: #008080\">  768 </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> trans… </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> Pretrained on BookCorpus and English W… </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                            efficientnet_b0 </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> image-t… </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> 1280 </span>│<span style=\"color: #008080; text-decoration-color: #008080\">    CNN </span>│<span style=\"color: #008080; text-decoration-color: #008080\">                  Pretrained on ImageNet </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                            efficientnet_b4 </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> image-t… </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> 1280 </span>│<span style=\"color: #008080; text-decoration-color: #008080\">    CNN </span>│<span style=\"color: #008080; text-decoration-color: #008080\">                  Pretrained on ImageNet </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                                        mlp </span>│<span style=\"color: #008080; text-decoration-color: #008080\">      any </span>│<span style=\"color: #008080; text-decoration-color: #008080\">    - </span>│<span style=\"color: #008080; text-decoration-color: #008080\">    MLP </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> Simple MLP encoder trained from scratch </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">               openai/clip-vit-base-patch32 </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> text-to… </span>│<span style=\"color: #008080; text-decoration-color: #008080\">  768 </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> trans… </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> Pretrained on text image pairs by Open… </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                                  resnet152 </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> image-t… </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> 2048 </span>│<span style=\"color: #008080; text-decoration-color: #008080\">    CNN </span>│<span style=\"color: #008080; text-decoration-color: #008080\">                  Pretrained on ImageNet </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                                   resnet50 </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> image-t… </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> 2048 </span>│<span style=\"color: #008080; text-decoration-color: #008080\">    CNN </span>│<span style=\"color: #008080; text-decoration-color: #008080\">                  Pretrained on ImageNet </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> sentence-transformers/msmarco-distilbert-… </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> text-to… </span>│<span style=\"color: #008080; text-decoration-color: #008080\">  768 </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> trans… </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> Pretrained BERT, fine-tuned on MS Marco </span>│\n",
       "└────────────────────────────────────────────┴──────────┴──────┴────────┴─────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                Finetuner backbones                                                \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m                                      name\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    task\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mout…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1marchi…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                            description\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m                           bert-base-cased\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36mtext-to…\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m 768\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36mtrans…\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36mPretrained on BookCorpus and English W…\u001b[0m\u001b[36m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m                           efficientnet_b0\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36mimage-t…\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m1280\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m   CNN\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m                 Pretrained on ImageNet\u001b[0m\u001b[36m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m                           efficientnet_b4\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36mimage-t…\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m1280\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m   CNN\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m                 Pretrained on ImageNet\u001b[0m\u001b[36m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m                                       mlp\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m     any\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m   -\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m   MLP\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36mSimple MLP encoder trained from scratch\u001b[0m\u001b[36m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m              openai/clip-vit-base-patch32\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36mtext-to…\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m 768\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36mtrans…\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36mPretrained on text image pairs by Open…\u001b[0m\u001b[36m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m                                 resnet152\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36mimage-t…\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m2048\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m   CNN\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m                 Pretrained on ImageNet\u001b[0m\u001b[36m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m                                  resnet50\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36mimage-t…\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m2048\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m   CNN\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m                 Pretrained on ImageNet\u001b[0m\u001b[36m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36msentence-transformers/msmarco-distilbert-…\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36mtext-to…\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m 768\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36mtrans…\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36mPretrained BERT, fine-tuned on MS Marco\u001b[0m\u001b[36m \u001b[0m│\n",
       "└────────────────────────────────────────────┴──────────┴──────┴────────┴─────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import finetuner\n",
    "finetuner.describe_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'create_run'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/louisbeaumont/Documents/brain/.obsidian/plugins/obsidian-search/jina_fine_tuning.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/louisbeaumont/Documents/brain/.obsidian/plugins/obsidian-search/jina_fine_tuning.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfinetuner\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/louisbeaumont/Documents/brain/.obsidian/plugins/obsidian-search/jina_fine_tuning.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Create an experiment\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/louisbeaumont/Documents/brain/.obsidian/plugins/obsidian-search/jina_fine_tuning.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# finetuner.create_experiment(name=\"finetune-obsidian\")\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/louisbeaumont/Documents/brain/.obsidian/plugins/obsidian-search/jina_fine_tuning.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m run \u001b[39m=\u001b[39m finetuner\u001b[39m.\u001b[39;49mfit(model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmsmarco-distilbert-base-v3\u001b[39;49m\u001b[39m\"\u001b[39;49m, train_data\u001b[39m=\u001b[39;49mtrain_da)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/louisbeaumont/Documents/brain/.obsidian/plugins/obsidian-search/jina_fine_tuning.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRun name: \u001b[39m\u001b[39m{\u001b[39;00mrun\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/louisbeaumont/Documents/brain/.obsidian/plugins/obsidian-search/jina_fine_tuning.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRun status: \u001b[39m\u001b[39m{\u001b[39;00mrun\u001b[39m.\u001b[39mstatus()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/brain/.obsidian/plugins/obsidian-search/env/lib/python3.8/site-packages/finetuner/__init__.py:163\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, train_data, eval_data, run_name, description, experiment_name, model_options, loss, miner, optimizer, learning_rate, epochs, batch_size, callbacks, scheduler_step, freeze, output_dim, cpu, num_workers)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[1;32m     95\u001b[0m     model: \u001b[39mstr\u001b[39m,\n\u001b[1;32m     96\u001b[0m     train_data: Union[\u001b[39mstr\u001b[39m, DocumentArray],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m     num_workers: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m,\n\u001b[1;32m    114\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Run:\n\u001b[1;32m    115\u001b[0m     \u001b[39m\"\"\"Start a finetuner run!\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \n\u001b[1;32m    117\u001b[0m \u001b[39m    :param model: The name of model to be fine-tuned. Run `finetuner.list_models()` or\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m        workers used by the dataloader.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mreturn\u001b[39;00m ft\u001b[39m.\u001b[39;49mcreate_run(\n\u001b[1;32m    164\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    165\u001b[0m         train_data\u001b[39m=\u001b[39;49mtrain_data,\n\u001b[1;32m    166\u001b[0m         eval_data\u001b[39m=\u001b[39;49meval_data,\n\u001b[1;32m    167\u001b[0m         run_name\u001b[39m=\u001b[39;49mrun_name,\n\u001b[1;32m    168\u001b[0m         description\u001b[39m=\u001b[39;49mdescription,\n\u001b[1;32m    169\u001b[0m         experiment_name\u001b[39m=\u001b[39;49mexperiment_name,\n\u001b[1;32m    170\u001b[0m         model_options\u001b[39m=\u001b[39;49mmodel_options,\n\u001b[1;32m    171\u001b[0m         loss\u001b[39m=\u001b[39;49mloss,\n\u001b[1;32m    172\u001b[0m         miner\u001b[39m=\u001b[39;49mminer,\n\u001b[1;32m    173\u001b[0m         optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    174\u001b[0m         learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[1;32m    175\u001b[0m         epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    176\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    177\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    178\u001b[0m         scheduler_step\u001b[39m=\u001b[39;49mscheduler_step,\n\u001b[1;32m    179\u001b[0m         freeze\u001b[39m=\u001b[39;49mfreeze,\n\u001b[1;32m    180\u001b[0m         output_dim\u001b[39m=\u001b[39;49moutput_dim,\n\u001b[1;32m    181\u001b[0m         cpu\u001b[39m=\u001b[39;49mcpu,\n\u001b[1;32m    182\u001b[0m         num_workers\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[1;32m    183\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/brain/.obsidian/plugins/obsidian-search/env/lib/python3.8/site-packages/finetuner/finetuner.py:156\u001b[0m, in \u001b[0;36mFinetuner.create_run\u001b[0;34m(self, model, train_data, eval_data, run_name, description, experiment_name, model_options, loss, miner, optimizer, learning_rate, epochs, batch_size, callbacks, scheduler_step, freeze, output_dim, cpu, num_workers)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     experiment \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_experiment(name\u001b[39m=\u001b[39mexperiment_name)\n\u001b[0;32m--> 156\u001b[0m \u001b[39mreturn\u001b[39;00m experiment\u001b[39m.\u001b[39;49mcreate_run(\n\u001b[1;32m    157\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m    158\u001b[0m     train_data\u001b[39m=\u001b[39mtrain_data,\n\u001b[1;32m    159\u001b[0m     eval_data\u001b[39m=\u001b[39meval_data,\n\u001b[1;32m    160\u001b[0m     run_name\u001b[39m=\u001b[39mrun_name,\n\u001b[1;32m    161\u001b[0m     description\u001b[39m=\u001b[39mdescription,\n\u001b[1;32m    162\u001b[0m     model_options\u001b[39m=\u001b[39mmodel_options \u001b[39mor\u001b[39;00m {},\n\u001b[1;32m    163\u001b[0m     loss\u001b[39m=\u001b[39mloss,\n\u001b[1;32m    164\u001b[0m     miner\u001b[39m=\u001b[39mminer,\n\u001b[1;32m    165\u001b[0m     optimizer\u001b[39m=\u001b[39moptimizer,\n\u001b[1;32m    166\u001b[0m     learning_rate\u001b[39m=\u001b[39mlearning_rate,\n\u001b[1;32m    167\u001b[0m     epochs\u001b[39m=\u001b[39mepochs,\n\u001b[1;32m    168\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m    169\u001b[0m     callbacks\u001b[39m=\u001b[39mcallbacks \u001b[39mor\u001b[39;00m [],\n\u001b[1;32m    170\u001b[0m     scheduler_step\u001b[39m=\u001b[39mscheduler_step,\n\u001b[1;32m    171\u001b[0m     freeze\u001b[39m=\u001b[39mfreeze,\n\u001b[1;32m    172\u001b[0m     output_dim\u001b[39m=\u001b[39moutput_dim,\n\u001b[1;32m    173\u001b[0m     cpu\u001b[39m=\u001b[39mcpu,\n\u001b[1;32m    174\u001b[0m     num_workers\u001b[39m=\u001b[39mnum_workers,\n\u001b[1;32m    175\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'create_run'"
     ]
    }
   ],
   "source": [
    "from docarray import DocumentArray\n",
    "import finetuner\n",
    "\n",
    "# Create an experiment\n",
    "# finetuner.create_experiment(name=\"finetune-obsidian\")\n",
    "\n",
    "run = finetuner.fit(model=\"msmarco-distilbert-base-v3\", train_data=train_da)\n",
    "print(f\"Run name: {run.name}\")\n",
    "print(f\"Run status: {run.status()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1b9c6ab40788434a9dc6c2c705b69ca9ae38e02bf92851a26786014023ad3be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
