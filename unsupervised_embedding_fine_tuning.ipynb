{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import obsidiantools.api as otools\n",
    "# two level above the current directory\n",
    "wkd = Path(os.getcwd()).parent.parent.parent\n",
    "vault = otools.Vault(wkd).connect().gather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list with sentences (1k - 100k sentences)\n",
    "corpus = []\n",
    "\n",
    "for k, v in vault.text_index.items():\n",
    "    corpus.append(f\"File:\\n{k}\\n\\nContent:\\n{v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, LoggingHandler\n",
    "from sentence_transformers import models, util, datasets, evaluation, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define your sentence transformer model using CLS pooling\n",
    "model_name = 'bert-base-uncased'\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "model_name = 'sentence-transformers/multi-qa-MiniLM-L6-cos-v1'\n",
    "# or reuse a pretrained model\n",
    "# model_name = './output/tsdae-model'\n",
    "word_embedding_model = models.Transformer(model_name)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), 'cls')\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "\n",
    "# regex to grab the file title from content (File:\\n(blabla))\n",
    "regex = re.compile(r\"File:\\n(.*)\")\n",
    "\n",
    "def search(query: str):\n",
    "    # Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "    top_k = min(5, len(corpus))\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        print(\n",
    "            regex.findall(corpus[idx])[0],\n",
    "            \"(Score: {:.4f})\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"monkeys\",\n",
    "    \"bias\",\n",
    "    \"multiverse\",\n",
    "    \"reinforcement learning\"\n",
    "]\n",
    "for query in queries:\n",
    "    search(query)\n",
    "    print(\"\\n---------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import evaluation\n",
    "sentences1 = ['Ant is the most successful species on Earth', 'Cooperating most of the time while punishing un-cooperating behaviours, with some forgiveness, is a very efficient strategy in a multiplayer game', 'There is light in the world, and it is us!']\n",
    "sentences2 = ['As life emerged from the primeval soup several billion ago, the molecules that caused themselves to be replicated at the expense of others became more numerous', 'Sharks, after eating a lot of fish have dirty teeth, they move to a place in the ocean to have their teeth cleaned by small fish, they could easily close their jaws when the fish is in it but if they do so, the others small fishes won\\'t be likely to cooperate with this shark in the future', 'dog food']\n",
    "scores = [0.6, 0.8, 0.2]\n",
    "\n",
    "evaluator = evaluation.EmbeddingSimilarityEvaluator(sentences1, sentences2, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the special denoising dataset that adds noise on-the-fly\n",
    "train_dataset = datasets.DenoisingAutoEncoderDataset(corpus)\n",
    "\n",
    "# DataLoader to batch your data\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Use the denoising auto-encoder loss\n",
    "train_loss = losses.DenoisingAutoEncoderLoss(model, decoder_name_or_path=model_name, tie_encoder_decoder=True)\n",
    "\n",
    "# Call the fit method\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=2,\n",
    "    weight_decay=0,\n",
    "    scheduler='constantlr',\n",
    "    optimizer_params={'lr': 3e-5},\n",
    "    show_progress_bar=True,\n",
    "    evaluator=evaluator,\n",
    "    evaluation_steps=500\n",
    ")\n",
    "\n",
    "model.save(f'output/{model_name}-obsidian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_to_hub(f\"{model_name.split('/')[-1]}-obsidian\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"monkeys\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1b9c6ab40788434a9dc6c2c705b69ca9ae38e02bf92851a26786014023ad3be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
